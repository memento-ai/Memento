# @memento-ai/embedding

## Description
The `@memento-ai/embedding` package provides functionality for generating text embeddings using the Ollama language model. Embeddings are vector representations of text that can be useful for various natural language processing tasks, such as text similarity, clustering, and classification.

## Key Features
- Generate embeddings for one or more text inputs
- Support for the 'nomic-embed-text' Ollama model (default)
- Efficient batch processing of multiple text inputs
- Customizable model selection
- Embeddings with a dimension of 768

## Usage and Examples

### Importing the Package
```typescript
import { MyEmbeddingFunction, embedding } from '@memento-ai/embedding';
```

### Creating an Instance
```typescript
// Using the default 'nomic-embed-text' model
const embeddingInstance = new MyEmbeddingFunction();

// Or specifying a custom model
const customEmbeddingInstance = new MyEmbeddingFunction('custom-model-name');
```

### Using the Default Instance
```typescript
import { embedding } from '@memento-ai/embedding';

// Generate embeddings for multiple texts
const texts = ['hello world', 'goodbye world'];
const embeddings = await embedding.generate(texts);
console.log(embeddings); // [[...], [...]]

// Generate a single embedding
const singleEmbedding = await embedding.generateOne('hello world');
console.log(singleEmbedding); // [...]
```

### Generating Embeddings
```typescript
const embeddingInstance = new MyEmbeddingFunction();

// Generate embeddings for multiple texts
const texts = ['hello world', 'goodbye world'];
const embeddings = await embeddingInstance.generate(texts);
console.log(embeddings); // [[...], [...]]

// Generate a single embedding
const singleEmbedding = await embeddingInstance.generateOne('hello world');
console.log(singleEmbedding); // [...]
```

### Embedding Dimensions
The embeddings generated by this package have a dimension of 768, as confirmed in the test file.

### Note on Ollama Configuration
This package assumes that Ollama is running locally on the default port (11434). Make sure Ollama is properly set up and running on your system before using this package.
